import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# 1ï¸âƒ£ åŠ è½½æ•°æ®
df = pd.read_csv('cell_features.csv')
df.columns = df.columns.str.strip()
df['frame'] = pd.to_numeric(df['frame'], errors='coerce')
df['cell_id'] = pd.to_numeric(df.iloc[:, 1], errors='coerce')  # ç»†èƒç¼–å·
df = df.dropna(subset=['frame', 'cell_id'])

# 2ï¸âƒ£ è®¡ç®—ç‰¹å¾
df['aspect_ratio'] = df['length'] / (df['area'] + 1e-6)
df['brightness_var'] = df['mean_intensity'].rolling(3).std().fillna(0)
df['motion_x'] = df.groupby('cell_id')['x'].diff().fillna(0)  # æ¯ä¸ªç»†èƒå•ç‹¬è®¡ç®—
df['motion_y'] = df.groupby('cell_id')['y'].diff().fillna(0)
df['speed'] = np.sqrt(df['motion_x'] ** 2 + df['motion_y'] ** 2)

df['perimeter'] = np.pi * (df['length'] + df['area'] / (df['length'] + 1e-6))
df['solidity'] = df['area'] / (df['perimeter'] + 1e-6)
df['eccentricity'] = np.sqrt(1 - (df['area'] / (df['length'] ** 2 + 1e-6)))
df['roundness'] = (4 * np.pi * df['area']) / (df['perimeter'] ** 2 + 1e-6)
df['intensity_variance'] = df.groupby('cell_id')['mean_intensity'].rolling(3).std().fillna(0).reset_index(level=0, drop=True)

# âœ… è®¡ç®— delta_frameï¼ˆå¸§é—´éš”ï¼‰â€”â€” ä»…åœ¨ç›¸åŒ cell_id å†…è®¡ç®—
df['delta_frame'] = df.groupby('cell_id')['frame'].diff().fillna(1)  # ä¿è¯ä¸è·¨ç»†èƒ

# 3ï¸âƒ£ é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡
features = ['x', 'y', 'area', 'length', 'mean_intensity', 'aspect_ratio', 'brightness_var',
            'speed', 'eccentricity', 'solidity', 'roundness', 'intensity_variance']
target = 'delta_frame'

# 4ï¸âƒ£ å½’ä¸€åŒ–
scaler_X = MinMaxScaler()
df[features] = scaler_X.fit_transform(df[features])
scaler_y = MinMaxScaler()
df[[target]] = scaler_y.fit_transform(df[[target]])

# 5ï¸âƒ£ å¤„ç† LSTM è¾“å…¥æ ¼å¼
X, y = [], []
window_size = 10

for cell_id, group in df.groupby('cell_id'):  # æŒ‰ç»†èƒç¼–å·åˆ†ç»„ï¼Œç‹¬ç«‹å¤„ç†æ¯ä¸ªç»†èƒçš„æ•°æ®
    if len(group) > window_size:
        for i in range(window_size, len(group)):
            X.append(group[features].iloc[i - window_size:i].values)
            y.append(group[target].iloc[i])

X = np.array(X)
y = np.array(y)

# 6ï¸âƒ£ åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# 7ï¸âƒ£ æ„å»º LSTM ç½‘ç»œ
model = Sequential([
    Bidirectional(LSTM(128, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])),
    BatchNormalization(),
    Dropout(0.3),

    Bidirectional(LSTM(64, return_sequences=False)),
    BatchNormalization(),
    Dropout(0.3),

    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),

    Dense(1, activation='relu')  # çº¦æŸ delta_frame > 0
])

# 8ï¸âƒ£ ç¼–è¯‘æ¨¡å‹
model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error')
model.summary()

# 9ï¸âƒ£ è®­ç»ƒæ¨¡å‹
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))

# ğŸ”Ÿ ç»˜åˆ¶æŸå¤±æ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

# 1ï¸âƒ£1ï¸âƒ£ é¢„æµ‹ & åå½’ä¸€åŒ–
y_pred = model.predict(X_test)
y_pred = scaler_y.inverse_transform(y_pred)  # åå½’ä¸€åŒ– delta_frame
y_test = scaler_y.inverse_transform(y_test.reshape(-1, 1))

# âœ… è®¡ç®—çœŸå®é¢„æµ‹çš„ frame å€¼
frame_start = df['frame'].iloc[len(X_train) + window_size]  # æµ‹è¯•é›†èµ·å§‹ frame
y_pred_frame = np.cumsum(y_pred) + frame_start  # é€’å¢å¸§

# è®¡ç®—å‡æ–¹è¯¯å·®
mse = np.mean((y_pred - y_test) ** 2)
print(f'Mean Squared Error: {mse}')

# 1ï¸âƒ£2ï¸âƒ£ å¯è§†åŒ–é¢„æµ‹ç»“æœ
plt.figure(figsize=(10, 6))
plt.plot(df['frame'].iloc[len(X_train) + window_size:len(X_train) + window_size + len(y_test)].values,
         label='True Frame')
plt.plot(y_pred_frame, label='Predicted Frame', linestyle='dashed')
plt.title('True vs Predicted Cell Division Frame')
plt.xlabel('Sample Index')
plt.ylabel('Frame')
plt.legend()
plt.show()
